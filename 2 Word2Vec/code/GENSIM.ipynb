{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "sns.set()\n",
    "rcParams['figure.figsize'] = (20,10)\n",
    "pd.options.display.max_columns = None\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn import functional as F\n",
    "device = 'cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take random 300 files\n",
    "file_names = pathlib.Path('../data/baomoi').glob('*.txt')\n",
    "sample_file_names = [str(file_name) for file_name in file_names]\n",
    "sample_file_names = np.random.choice(sample_file_names, 10, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['../data/baomoi/0477-baomoi-articles.txt',\n",
       "       '../data/baomoi/1584-baomoi-articles.txt',\n",
       "       '../data/baomoi/1665-baomoi-articles.txt',\n",
       "       '../data/baomoi/1199-baomoi-articles.txt',\n",
       "       '../data/baomoi/0878-baomoi-articles.txt',\n",
       "       '../data/baomoi/0488-baomoi-articles.txt',\n",
       "       '../data/baomoi/1381-baomoi-articles.txt',\n",
       "       '../data/baomoi/1406-baomoi-articles.txt',\n",
       "       '../data/baomoi/0042-baomoi-articles.txt',\n",
       "       '../data/baomoi/1483-baomoi-articles.txt'], dtype='<U42')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "332e657aa1584b55bd756eefc008f7bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# open all_simplified2.txt and append to it\n",
    "with open('../data/all_simplified2.txt', 'a') as f_all:\n",
    "  for file_name in tqdm(sample_file_names):\n",
    "    try:\n",
    "      with open(file_name, 'r') as f:\n",
    "        f_all.write(f.read())\n",
    "        f_all.write('\\n')\n",
    "    except:\n",
    "      continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.models.word2vec import LineSentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103736154, 133138401)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train word2vec model\n",
    "model = Word2Vec(LineSentence('../data/all_simplified2.txt'), vector_size=100, window=5, min_count=5, workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_func():\n",
    "    return model.wv.words_closer_than('trump', 'biden')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hoàng_đế', 0.7591509819030762)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['trai', 'vua'], negative=['gái'], topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hoàng_đế', 0.7591509819030762)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['trai','vua'], negative=['gái'], topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('chính_xác', 0.5738757252693176)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['đúng','sai'], negative=['trắng'], topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('em', 0.7648999094963074),\n",
       " ('mình', 0.7570592164993286),\n",
       " ('chúng_em', 0.7095321416854858),\n",
       " ('họ', 0.7060391902923584),\n",
       " ('chúng_tôi', 0.6993587017059326),\n",
       " ('con_bé', 0.691789448261261),\n",
       " ('ba_mẹ', 0.6915090680122375),\n",
       " ('anh', 0.6671024560928345),\n",
       " ('kathy', 0.665908932685852),\n",
       " ('bố_mẹ', 0.6624516248703003)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(['tôi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../data/w2v.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "model = Word2Vec.load('../data/word2vec.model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
